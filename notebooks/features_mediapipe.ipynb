{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ca8730",
   "metadata": {},
   "source": [
    "# Extracción de landmarks y features con MediaPipe\n",
    "\n",
    "Este notebook procesa los videos de `data/raw/`, extrae los landmarks con MediaPipe, calcula features cinemáticas y exporta un archivo tabular listo para modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0cf811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>end_frame</th>\n",
       "      <th>actividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a327f941-Video_1.mp4</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>parandose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a327f941-Video_1.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>sentado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a327f941-Video_1.mp4</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>parado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a327f941-Video_1.mp4</td>\n",
       "      <td>40</td>\n",
       "      <td>119</td>\n",
       "      <td>caminando adelante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a327f941-Video_1.mp4</td>\n",
       "      <td>120</td>\n",
       "      <td>155</td>\n",
       "      <td>girando</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  video  start_frame  end_frame           actividad\n",
       "0  a327f941-Video_1.mp4           18         37           parandose\n",
       "1  a327f941-Video_1.mp4            1         18             sentado\n",
       "2  a327f941-Video_1.mp4           37         40              parado\n",
       "3  a327f941-Video_1.mp4           40        119  caminando adelante\n",
       "4  a327f941-Video_1.mp4          120        155             girando"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Directorio de videos y etiquetas\n",
    "videos_dir = Path('../data/raw')\n",
    "etiquetas_path = Path('../results/labels_por_rango.csv')\n",
    "\n",
    "# Cargar etiquetas por rango de frames\n",
    "df_labels = pd.read_csv(etiquetas_path)\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ebeb96",
   "metadata": {},
   "source": [
    "## Funciones auxiliares para extracción de features\n",
    "\n",
    "Incluye funciones para calcular ángulos, distancias y buscar la etiqueta de actividad para cada frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95bdd7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_for_frame(df_labels, video_file, frame_idx):\n",
    "    \"\"\"Busca la etiqueta de actividad para un frame dado de un video.\"\"\"\n",
    "    rows = df_labels[df_labels['video'] == video_file]\n",
    "    for _, row in rows.iterrows():\n",
    "        if row['start_frame'] <= frame_idx <= row['end_frame']:\n",
    "            return row['actividad']\n",
    "    return None\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calcula el ángulo (en grados) entre tres puntos (b es el vértice).\"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cos_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def calculate_distance(p1, p2):\n",
    "    p1 = np.array(p1)\n",
    "    p2 = np.array(p2)\n",
    "    return np.linalg.norm(p1 - p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75964fd1",
   "metadata": {},
   "source": [
    "## Extracción de features por ventana\n",
    "\n",
    "Procesa cada video, extrae landmarks con MediaPipe y calcula features agregadas por ventana (media, std, min, max de ángulos, distancias, inclinaciones, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033e67d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video:  ..\\data\\raw\\Video 1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\RonyOz\\py\\video-annotation-system\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video:  ..\\data\\raw\\Video 10.mp4\n",
      "Video:  ..\\data\\raw\\Video 11.mp4\n",
      "Video:  ..\\data\\raw\\Video 11.mp4\n",
      "Video:  ..\\data\\raw\\Video 12.mp4\n",
      "Video:  ..\\data\\raw\\Video 12.mp4\n",
      "Video:  ..\\data\\raw\\Video 13.mp4\n",
      "Video:  ..\\data\\raw\\Video 13.mp4\n",
      "Video:  ..\\data\\raw\\Video 14.mp4\n",
      "Video:  ..\\data\\raw\\Video 14.mp4\n",
      "Video:  ..\\data\\raw\\Video 15.mp4\n",
      "Video:  ..\\data\\raw\\Video 15.mp4\n",
      "Video:  ..\\data\\raw\\Video 16.mp4\n",
      "Video:  ..\\data\\raw\\Video 16.mp4\n",
      "Video:  ..\\data\\raw\\Video 17.mp4\n",
      "Video:  ..\\data\\raw\\Video 17.mp4\n",
      "Video:  ..\\data\\raw\\Video 18.mp4\n",
      "Video:  ..\\data\\raw\\Video 18.mp4\n",
      "Video:  ..\\data\\raw\\Video 2.mp4\n",
      "Video:  ..\\data\\raw\\Video 2.mp4\n",
      "Video:  ..\\data\\raw\\Video 3.mp4\n",
      "Video:  ..\\data\\raw\\Video 3.mp4\n",
      "Video:  ..\\data\\raw\\Video 4.mp4\n",
      "Video:  ..\\data\\raw\\Video 4.mp4\n",
      "Video:  ..\\data\\raw\\Video 5.mp4\n",
      "Video:  ..\\data\\raw\\Video 5.mp4\n",
      "Video:  ..\\data\\raw\\Video 6.mp4\n",
      "Video:  ..\\data\\raw\\Video 6.mp4\n",
      "Video:  ..\\data\\raw\\Video 7.mp4\n",
      "Video:  ..\\data\\raw\\Video 7.mp4\n",
      "Video:  ..\\data\\raw\\Video 8.mp4\n",
      "Video:  ..\\data\\raw\\Video 8.mp4\n",
      "Video:  ..\\data\\raw\\Video 9.mp4\n",
      "Video:  ..\\data\\raw\\Video 9.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>end_frame</th>\n",
       "      <th>knee_angle_mean</th>\n",
       "      <th>knee_angle_std</th>\n",
       "      <th>trunk_incl_mean</th>\n",
       "      <th>trunk_incl_std</th>\n",
       "      <th>dist_sh_hip_mean</th>\n",
       "      <th>dist_sh_hip_std</th>\n",
       "      <th>actividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [video, start_frame, end_frame, knee_angle_mean, knee_angle_std, trunk_incl_mean, trunk_incl_std, dist_sh_hip_mean, dist_sh_hip_std, actividad]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Parámetros de la ventana\n",
    "target_fps = 30  # Ajusta según tus videos\n",
    "window_size = int(0.5 * target_fps)  # 0.5 segundos\n",
    "step_size = int(0.25 * target_fps)   # 50% solapamiento\n",
    "\n",
    "features_list = []\n",
    "\n",
    "for video_path in videos_dir.glob('*.mp4'):\n",
    "    print(\"Video: \",video_path)\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    video_file = video_path.name\n",
    "    frame_landmarks = []\n",
    "    frame_idx = 0\n",
    "    with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5) as pose:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(frame_rgb)\n",
    "            if results.pose_landmarks:\n",
    "                # Extraer solo los landmarks relevantes (ejemplo: cadera, rodilla, tobillo, hombro)\n",
    "                lm = results.pose_landmarks.landmark\n",
    "                # Ejemplo: cadera izq (23), rodilla izq (25), tobillo izq (27), hombro izq (11)\n",
    "                coords = {\n",
    "                    'hip': (lm[23].x, lm[23].y),\n",
    "                    'knee': (lm[25].x, lm[25].y),\n",
    "                    'ankle': (lm[27].x, lm[27].y),\n",
    "                    'shoulder': (lm[11].x, lm[11].y)\n",
    "                }\n",
    "                frame_landmarks.append(coords)\n",
    "            else:\n",
    "                frame_landmarks.append(None)\n",
    "            frame_idx += 1\n",
    "    cap.release()\n",
    "\n",
    "    # Procesar por ventana\n",
    "    n_frames = len(frame_landmarks)\n",
    "    for start in range(0, n_frames - window_size + 1, step_size):\n",
    "        window = frame_landmarks[start:start+window_size]\n",
    "        # Filtrar frames válidos\n",
    "        window = [f for f in window if f is not None]\n",
    "        if len(window) < window_size * 0.7:\n",
    "            continue  # Demasiados frames perdidos\n",
    "        # Calcular features agregadas\n",
    "        hips = np.array([f['hip'] for f in window])\n",
    "        knees = np.array([f['knee'] for f in window])\n",
    "        ankles = np.array([f['ankle'] for f in window])\n",
    "        shoulders = np.array([f['shoulder'] for f in window])\n",
    "        # Ángulo rodilla (media, std)\n",
    "        knee_angles = [calculate_angle(hip, knee, ankle) for hip, knee, ankle in zip(hips, knees, ankles)]\n",
    "        # Inclinación tronco (ángulo entre hombro-cadera y vertical)\n",
    "        trunk_incl = [np.degrees(np.arctan2(s[0]-h[0], h[1]-s[1])) for s, h in zip(shoulders, hips)]\n",
    "        # Distancia hombro-cadera\n",
    "        dist_sh_hip = [calculate_distance(s, h) for s, h in zip(shoulders, hips)]\n",
    "        # Features agregadas\n",
    "        feats = {\n",
    "            'video': video_file,\n",
    "            'start_frame': start,\n",
    "            'end_frame': start+window_size-1,\n",
    "            'knee_angle_mean': np.mean(knee_angles),\n",
    "            'knee_angle_std': np.std(knee_angles),\n",
    "            'trunk_incl_mean': np.mean(trunk_incl),\n",
    "            'trunk_incl_std': np.std(trunk_incl),\n",
    "            'dist_sh_hip_mean': np.mean(dist_sh_hip),\n",
    "            'dist_sh_hip_std': np.std(dist_sh_hip)\n",
    "        }\n",
    "        # Etiqueta de actividad para la ventana (mayoría de frames)\n",
    "        labels = [get_activity_for_frame(df_labels, video_file, f) for f in range(start, start+window_size)]\n",
    "        feats['actividad'] = max(set(labels), key=labels.count) if labels else None\n",
    "        features_list.append(feats)\n",
    "\n",
    "# Guardar features\n",
    "features_df = pd.DataFrame(features_list)\n",
    "features_df = features_df.dropna()\n",
    "features_df.to_csv('../results/features.csv', index=False)\n",
    "features_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
